{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Docugami KG-RAG against OpenAI Assistants Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Eval Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "DOCSET_NAME = \"Earnings Calls Evaluation\"\n",
    "FILE_NAMES = [\n",
    "    \"Q1 2022 Snowflake Inc. Earnings Call - Snowflake Inc - BamSEC.pdf\",\n",
    "    \"Q1 2023 Snowflake Inc. Earnings Call - Snowflake Inc - BamSEC.pdf\",\n",
    "    \"Q2 2022 Snowflake Inc. Earnings Call - Snowflake Inc - BamSEC.pdf\",\n",
    "    \"Q2 2023 Snowflake Inc. Earnings Call - Snowflake Inc - BamSEC.pdf\",\n",
    "    \"Q3 2021 Snowflake Inc. Earnings Call - Snowflake Inc - BamSEC.pdf\",\n",
    "    \"Q3 2022 Snowflake Inc. Earnings Call - Snowflake Inc - BamSEC.pdf\",\n",
    "    \"Q3 2023 Snowflake Inc. Earnings Call - Snowflake Inc - BamSEC.pdf\",\n",
    "    \"Q4 2020 Snowflake Inc. Earnings Call - Snowflake Inc - BamSEC.pdf\",\n",
    "    \"Q4 2022 Snowflake Inc. Earnings Call - Snowflake Inc - BamSEC.pdf\",\n",
    "    \"Q3 FY23 Microsoft Corp Earnings Call.pdf\",\n",
    "]\n",
    "\n",
    "FILES_DIR = Path(os.getcwd()) / \"v1/docs\"\n",
    "GROUND_TRUTH_CSV = Path(os.getcwd()) / \"v1/ground-truth-earning_calls.csv\"\n",
    "\n",
    "# Note: Please specify ~6 (or more!) similar files to process together as a document set\n",
    "# This is currently a requirement for Docugami to automatically detect motifs\n",
    "# across the document set to generate a semantic XML Knowledge Graph.\n",
    "assert len(FILE_NAMES) >= 6, \"Please provide at least 6 files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langsmith import Client\n",
    "\n",
    "# Read\n",
    "df = pd.read_csv(GROUND_TRUTH_CSV)\n",
    "\n",
    "# Dataset\n",
    "client = Client()\n",
    "dataset_name = DOCSET_NAME\n",
    "existing_datasets = list(client.list_datasets(dataset_name=dataset_name))\n",
    "if existing_datasets:\n",
    "    # read existing dataset\n",
    "    dataset = client.read_dataset(dataset_name=dataset_name)\n",
    "else:\n",
    "    dataset = client.create_dataset(dataset_name=dataset_name)\n",
    "    # Populate dataset\n",
    "    for _, row in df.iterrows():\n",
    "        q = row[\"Question\"]\n",
    "        a = row[\"Answer\"]\n",
    "        client.create_example(\n",
    "            inputs={\"question\": q}, outputs={\"answer\": a}, dataset_id=dataset.id\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Docugami KG-RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pip --quiet --upgrade\n",
    "! pip install docugami==0.0.9 dgml-utils==0.3.0 --quiet --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload files to Docugami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docugami import Docugami\n",
    "from docugami.lib.upload import upload_to_named_docset, wait_for_dgml\n",
    "\n",
    "dg_client = Docugami()\n",
    "file_paths = [FILES_DIR / file_name for file_name in FILE_NAMES]\n",
    "\n",
    "# Files will not be re-uploaded if they were previously uploaded (based on name)\n",
    "dg_docs = upload_to_named_docset(dg_client, file_paths, DOCSET_NAME)\n",
    "\n",
    "docset_id = \"\"\n",
    "docset_name = \"\"\n",
    "for doc in dg_docs:\n",
    "    if not docset_id:\n",
    "        docset_id = doc.docset.id\n",
    "    else:\n",
    "        # all docs must be in the same docset\n",
    "        assert docset_id == doc.docset.id\n",
    "\n",
    "    if not docset_name:\n",
    "        docset_name = dg_client.docsets.retrieve(doc.docset.id).name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for files to finish processing (OCR, and zero-shot creation of XML knowledge graph)\n",
    "\n",
    "# Note: This can take some time on the free docugami tier (up to ~20 mins). Please contact us for faster paid plans.\n",
    "wait_for_dgml(dg_client, dg_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run indexing\n",
    "from docugami_kg_rag.helpers.indexing import index_docset\n",
    "\n",
    "assert docset_id\n",
    "assert docset_name\n",
    "\n",
    "# Note: This can take some time since it is embedding and creating summaries for all the docs and chunks\n",
    "index_docset(docset_id=docset_id, name=docset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Docugami Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "from docugami_kg_rag.chain import agent as docugami_agent, _get_tools, AgentInput\n",
    "\n",
    "def predict_docugami_agent(input: dict) -> dict:\n",
    "    question = input[\"question\"]\n",
    "    chain = AgentExecutor(\n",
    "        agent=docugami_agent,\n",
    "        tools=_get_tools(),\n",
    "    ).with_types(\n",
    "        input_type=AgentInput,\n",
    "    )\n",
    "    result = chain.invoke({\n",
    "        \"input\": question,\n",
    "        \"use_reports\": False,\n",
    "        \"chat_history\": [],\n",
    "    })\n",
    "\n",
    "    return result[\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the agent to make sure it is working\n",
    "predict_docugami_agent({\"question\": \"What was the question from Barclays in the Q2 2023 earnings call?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up OpenAI Assistants Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install openai --upgrade --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload files to OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import files\n",
    "\n",
    "existing_files = files.list().data\n",
    "existing_file_names = [f.filename for f in existing_files]\n",
    "uploaded_files = []\n",
    "for file_name in FILE_NAMES:\n",
    "    if file_name in existing_file_names:\n",
    "        # file was previously uploaded\n",
    "        uploaded_files.append([f for f in existing_files if f.filename == file_name][0])\n",
    "    else:\n",
    "        # upload\n",
    "        file_path = FILES_DIR / file_name\n",
    "        file = files.create(file=file_path, purpose='assistants')\n",
    "        uploaded_files.append(file)\n",
    "\n",
    "file_ids=[f.id for f in uploaded_files]\n",
    "\n",
    "uploaded_files\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create OpenAI Assistant Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.openai_assistant import OpenAIAssistantRunnable\n",
    "openai_agent = OpenAIAssistantRunnable.create_assistant(\n",
    "    name=\"Earnings Call Assistant\",\n",
    "    instructions=\"An assistant that specializes in answering questions based only on the given knowledge base of earnings calls\",\n",
    "    tools=[{\"type\": \"retrieval\"}],\n",
    "    model=\"gpt-4-1106-preview\",\n",
    ")\n",
    "openai_agent.as_agent = True\n",
    "\n",
    "def predict_openai_agent(input: dict) -> dict:\n",
    "    question = input[\"question\"]\n",
    "    result = openai_agent.invoke({\n",
    "        \"content\": question,\n",
    "        \"file_ids\": file_ids,\n",
    "    })\n",
    "\n",
    "    return result.return_values[\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the agent to make sure it is working\n",
    "predict_openai_agent({\"question\": \"What was the question from Barclays in the Q2 2023 earnings call?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Evals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from langsmith.client import Client\n",
    "from langchain.smith import RunEvalConfig\n",
    "\n",
    "eval_config = RunEvalConfig(\n",
    "    evaluators=[\"cot_qa\"],\n",
    ")\n",
    "\n",
    "def run_eval(eval_func, eval_run_name):\n",
    "    \"\"\"\n",
    "    Run eval\n",
    "    \"\"\"\n",
    "    client = Client()\n",
    "    client.run_on_dataset(\n",
    "        dataset_name=DOCSET_NAME,\n",
    "        llm_or_chain_factory=eval_func,\n",
    "        evaluation=eval_config,\n",
    "        verbose=True,\n",
    "        project_name=eval_run_name,\n",
    "    )\n",
    "\n",
    "\n",
    "# Experiments\n",
    "agent_map = {\n",
    "    \"docugami_kg_rag_zero_shot\": predict_docugami_agent,\n",
    "    \"openai_assistant_retrieval\": predict_openai_agent,\n",
    "}\n",
    "\n",
    "for _ in range(10):\n",
    "    run_id = str(uuid.uuid4())\n",
    "    for project_name, agent in agent_map.items():\n",
    "        run_eval(agent, project_name + \"_\" + run_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "app-sMPCFT4i-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
